{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54822d94",
   "metadata": {},
   "source": [
    "# Wine Quality Analysis with Advanced ML Techniques & Visualizations\n",
    "\n",
    "Welcome to the Wine Quality Analysis notebook! Here, we teach machines to appreciate fine wine (so we don't have to). This analysis features advanced machine learning, feature engineering, and ensemble modeling, all sprinkled with attempts at humor to keep things lively. üç∑üìä\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc17789",
   "metadata": {},
   "source": [
    "## 1. Load Required Libraries\n",
    "\n",
    "We'll install and load all the necessary R packages for data wrangling, visualization, and machine learning. We're loading more packages than a wine tasting has bottles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd3bc97",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Start timing\n",
    "start_time <- Sys.time()\n",
    "\n",
    "# Load and install required libraries\n",
    "required_libs <- c(\"tidyverse\", \"caret\", \"randomForest\", \"e1071\", \"nnet\", \"corrplot\", \"RCurl\", \"reshape2\")\n",
    "for (lib in required_libs) {\n",
    "  if (!require(lib, character.only = TRUE)) {\n",
    "    # Installing packages... this might take longer than aging a fine wine\n",
    "    install.packages(lib, repos = \"http://cran.us.r-project.org\")\n",
    "    library(lib, character.only = TRUE)\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daffc6c5",
   "metadata": {},
   "source": [
    "## 2. Download and Prepare Wine Quality Data\n",
    "\n",
    "We'll download the red and white wine datasets, add wine type labels, and combine them into a single dataframe. Mixing red and white wines together: a sommelier's nightmare, a data scientist's dream!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb99feaf",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cat(\"Downloading wine quality datasets...\\n\")\n",
    "options(timeout = 300)  # Setting timeout to 5 minutes\n",
    "\n",
    "# Download red wine data\n",
    "red_url <- \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "red_wine_raw <- read.csv(red_url, sep = \";\", header = TRUE)\n",
    "red_wine_raw$wine_type <- \"red\"\n",
    "\n",
    "# Download white wine data\n",
    "white_url <- \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "white_wine_raw <- read.csv(white_url, sep = \";\", header = TRUE)\n",
    "white_wine_raw$wine_type <- \"white\"\n",
    "\n",
    "# Combine datasets\n",
    "wine_data <- rbind(red_wine_raw, white_wine_raw)\n",
    "cat(\"Combined dataset size:\", nrow(wine_data), \"wines\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aec1136",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Feature Engineering\n",
    "\n",
    "We'll create categorical quality labels, engineer new features, and handle missing values. Because wine relationships are complex, we're adding polynomial features and interactions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9cfe86",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "wine_data <- wine_data %>%\n",
    "  mutate(\n",
    "    # Create quality categories for classification\n",
    "    quality_category = case_when(\n",
    "      quality <= 5 ~ \"Low\",      # \"Meh, I've had worse\"\n",
    "      quality <= 7 ~ \"Medium\",   # \"Not bad, would drink at a wedding\"\n",
    "      TRUE ~ \"High\"              # \"Actually worth the price tag\"\n",
    "    ),\n",
    "    quality_category = factor(quality_category, levels = c(\"Low\", \"Medium\", \"High\")),\n",
    "    wine_type = factor(wine_type),\n",
    "    \n",
    "    # Engineered features\n",
    "    acid_ratio = fixed.acidity / volatile.acidity,\n",
    "    sugar_alcohol_ratio = residual.sugar / alcohol,\n",
    "    sulfur_ratio = free.sulfur.dioxide / total.sulfur.dioxide,\n",
    "    total_acidity = fixed.acidity + volatile.acidity + citric.acid,\n",
    "    alcohol_sugar_interaction = alcohol * residual.sugar,\n",
    "    density_alcohol_ratio = density / alcohol,\n",
    "    ph_acidity_balance = pH * total_acidity,\n",
    "    preservation_index = total.sulfur.dioxide / density,\n",
    "    quality_compounds = sulphates * citric.acid,\n",
    "    alcohol_squared = alcohol^2,\n",
    "    volatile_acidity_squared = volatile.acidity^2,\n",
    "    wine_type_numeric = ifelse(wine_type == \"red\", 1, 0),\n",
    "    red_wine_alcohol = wine_type_numeric * alcohol,\n",
    "    white_wine_sugar = (1 - wine_type_numeric) * residual.sugar\n",
    "  ) %>%\n",
    "  na.omit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384e3f48",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis\n",
    "\n",
    "Let's display basic statistics and distributions for wine quality and wine type. No room for incomplete wines in our analysis (or wine cellar)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd54b6b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cat(\"\\nQuality distribution:\\n\")\n",
    "print(table(wine_data$quality_category))\n",
    "cat(\"\\nWine type distribution:\\n\") \n",
    "print(table(wine_data$wine_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4069b06b",
   "metadata": {},
   "source": [
    "## 5. Visualizations\n",
    "\n",
    "Time to make this data prettier than a vineyard at sunset! We'll generate bar plots, correlation heatmaps, and boxplots to explore data relationships and feature distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7cb68a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Plot 1: Quality Distribution\n",
    "library(ggplot2)\n",
    "p1 <- wine_data %>%\n",
    "  ggplot(aes(x = quality_category, fill = quality_category)) +\n",
    "  geom_bar(alpha = 0.8) +\n",
    "  geom_text(stat = 'count', aes(label = after_stat(count)), vjust = -0.5) +\n",
    "  labs(title = \"Distribution of Wine Quality Categories\",\n",
    "       subtitle = \"Most wines are mediocre - just like my cooking\",\n",
    "       x = \"Quality Category\", \n",
    "       y = \"Number of Wines\") +\n",
    "  scale_fill_manual(values = c(\"Low\" = \"#FF6B6B\", \"Medium\" = \"#4ECDC4\", \"High\" = \"#45B7D1\")) +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"none\",\n",
    "        plot.title = element_text(size = 14, face = \"bold\"),\n",
    "        plot.subtitle = element_text(size = 12))\n",
    "print(p1)\n",
    "\n",
    "# Plot 2: Correlation Heatmap\n",
    "cor_data <- wine_data %>%\n",
    "  select(fixed.acidity, volatile.acidity, citric.acid, residual.sugar, \n",
    "         chlorides, free.sulfur.dioxide, total.sulfur.dioxide, \n",
    "         density, pH, sulphates, alcohol, quality) %>%\n",
    "  cor()\n",
    "cor_melted <- reshape2::melt(cor_data)\n",
    "names(cor_melted) <- c(\"Var1\", \"Var2\", \"value\")\n",
    "p2 <- cor_melted %>%\n",
    "  ggplot(aes(Var1, Var2, fill = value)) +\n",
    "  geom_tile(color = \"white\") +\n",
    "  scale_fill_gradient2(low = \"blue\", high = \"red\", mid = \"white\", \n",
    "                       midpoint = 0, limit = c(-1,1), space = \"Lab\",\n",
    "                       name=\"Correlation\") +\n",
    "  theme_minimal() +\n",
    "  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),\n",
    "        plot.title = element_text(size = 14, face = \"bold\")) +\n",
    "  labs(title = \"Wine Chemistry Relationships\",\n",
    "       subtitle = \"More complex than a sommelier's tasting notes\",\n",
    "       x = \"\", y = \"\") +\n",
    "  coord_fixed()\n",
    "print(p2)\n",
    "\n",
    "# Plot 3: Alcohol Content by Quality\n",
    "p3 <- wine_data %>%\n",
    "  ggplot(aes(x = quality_category, y = alcohol, fill = quality_category)) +\n",
    "  geom_boxplot(alpha = 0.8, outlier.alpha = 0.5) +\n",
    "  geom_jitter(alpha = 0.3, width = 0.2, size = 0.5) +\n",
    "  labs(title = \"Alcohol Content vs Wine Quality\",\n",
    "       subtitle = \"Higher alcohol = Better wine. I don't make the rules.\",\n",
    "       x = \"Quality Category\",\n",
    "       y = \"Alcohol Content (%)\") +\n",
    "  scale_fill_manual(values = c(\"Low\" = \"#FF6B6B\", \"Medium\" = \"#4ECDC4\", \"High\" = \"#45B7D1\")) +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"none\",\n",
    "        plot.title = element_text(size = 14, face = \"bold\"),\n",
    "        plot.subtitle = element_text(size = 12))\n",
    "print(p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab7688e",
   "metadata": {},
   "source": [
    "## 6. Train/Test/Validation Split\n",
    "\n",
    "We'll split the data into training, validation, and test sets for model evaluation. Set seed for reproducibility‚Äîlike a good vintage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae67c5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(42)\n",
    "test_index <- createDataPartition(y = wine_data$quality_category, times = 1, p = 0.2, list = FALSE)\n",
    "train_set <- wine_data[-test_index,]\n",
    "test_set <- wine_data[test_index,]\n",
    "\n",
    "set.seed(42)\n",
    "val_index <- createDataPartition(y = train_set$quality_category, times = 1, p = 0.2, list = FALSE)\n",
    "validation_set <- train_set[val_index,]\n",
    "train_set_final <- train_set[-val_index,]\n",
    "\n",
    "cat(\"Training set size:\", nrow(train_set_final), \"\\n\")\n",
    "cat(\"Validation set size:\", nrow(validation_set), \"\\n\") \n",
    "cat(\"Test set size:\", nrow(test_set), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea2a8c9",
   "metadata": {},
   "source": [
    "## 7. Model Training: Baseline, Random Forest, SVM, Neural Network, Enhanced Random Forest\n",
    "\n",
    "We'll train multiple models and evaluate their validation accuracy. It's a model beauty contest‚Äîmay the best classifier win!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1f7969",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Define accuracy function\n",
    "accuracy_func <- function(actual, predicted) {\n",
    "  mean(actual == predicted)\n",
    "}\n",
    "\n",
    "# Feature columns\n",
    "feature_cols <- c(\"fixed.acidity\", \"volatile.acidity\", \"citric.acid\", \"residual.sugar\",\n",
    "                  \"chlorides\", \"free.sulfur.dioxide\", \"total.sulfur.dioxide\", \"density\", \n",
    "                  \"pH\", \"sulphates\", \"alcohol\", \"wine_type\", \"acid_ratio\", \n",
    "                  \"sugar_alcohol_ratio\", \"sulfur_ratio\", \"total_acidity\",\n",
    "                  \"alcohol_sugar_interaction\", \"density_alcohol_ratio\", \"ph_acidity_balance\",\n",
    "                  \"preservation_index\", \"quality_compounds\", \"alcohol_squared\",\n",
    "                  \"volatile_acidity_squared\", \"red_wine_alcohol\", \"white_wine_sugar\")\n",
    "\n",
    "results_df <- data.frame(Method = character(), Accuracy = numeric(), stringsAsFactors = FALSE)\n",
    "\n",
    "# Method 1: Baseline\n",
    "baseline_pred <- rep(names(sort(table(train_set_final$quality_category), decreasing = TRUE))[1], \n",
    "                     nrow(validation_set))\n",
    "baseline_accuracy <- accuracy_func(validation_set$quality_category, baseline_pred)\n",
    "results_df <- rbind(results_df, data.frame(Method = \"Baseline (Most Frequent)\", Accuracy = baseline_accuracy))\n",
    "\n",
    "cat(\"Method 1 completed: Baseline\\n\")\n",
    "\n",
    "# Method 2: Random Forest\n",
    "set.seed(42)\n",
    "rf_model <- randomForest(quality_category ~ ., \n",
    "                         data = train_set_final[, c(feature_cols, \"quality_category\")],\n",
    "                         ntree = 500,\n",
    "                         mtry = 8,\n",
    "                         importance = TRUE)\n",
    "rf_pred <- predict(rf_model, validation_set)\n",
    "rf_accuracy <- accuracy_func(validation_set$quality_category, rf_pred)\n",
    "results_df <- rbind(results_df, data.frame(Method = \"Random Forest\", Accuracy = rf_accuracy))\n",
    "\n",
    "cat(\"Method 2 completed: Random Forest\\n\")\n",
    "\n",
    "# Method 3: SVM (RBF Kernel)\n",
    "set.seed(42)\n",
    "svm_model <- svm(quality_category ~ ., \n",
    "                 data = train_set_final[, c(feature_cols, \"quality_category\")],\n",
    "                 kernel = \"radial\",\n",
    "                 cost = 1,\n",
    "                 gamma = 0.1,\n",
    "                 probability = TRUE)\n",
    "svm_pred <- predict(svm_model, validation_set)\n",
    "svm_accuracy <- accuracy_func(validation_set$quality_category, svm_pred)\n",
    "results_df <- rbind(results_df, data.frame(Method = \"SVM (RBF Kernel)\", Accuracy = svm_accuracy))\n",
    "\n",
    "cat(\"Method 3 completed: SVM\\n\")\n",
    "\n",
    "# Method 4: Neural Network\n",
    "set.seed(42)\n",
    "numeric_cols <- c(\"fixed.acidity\", \"volatile.acidity\", \"citric.acid\", \"residual.sugar\",\n",
    "                  \"chlorides\", \"free.sulfur.dioxide\", \"total.sulfur.dioxide\", \"density\", \n",
    "                  \"pH\", \"sulphates\", \"alcohol\", \"acid_ratio\", \"sugar_alcohol_ratio\", \n",
    "                  \"sulfur_ratio\", \"total_acidity\", \"alcohol_sugar_interaction\",\n",
    "                  \"density_alcohol_ratio\", \"ph_acidity_balance\", \"preservation_index\",\n",
    "                  \"quality_compounds\", \"alcohol_squared\", \"volatile_acidity_squared\",\n",
    "                  \"red_wine_alcohol\", \"white_wine_sugar\")\n",
    "train_scaled <- train_set_final\n",
    "validation_scaled <- validation_set\n",
    "for(col in numeric_cols) {\n",
    "  col_mean <- mean(train_set_final[[col]])\n",
    "  col_sd <- sd(train_set_final[[col]])\n",
    "  train_scaled[[col]] <- (train_set_final[[col]] - col_mean) / col_sd\n",
    "  validation_scaled[[col]] <- (validation_set[[col]] - col_mean) / col_sd\n",
    "}\n",
    "nn_model <- nnet(quality_category ~ ., \n",
    "                 data = train_scaled[, c(feature_cols, \"quality_category\")],\n",
    "                 size = 15,\n",
    "                 decay = 0.1,\n",
    "                 maxit = 300,\n",
    "                 trace = FALSE)\n",
    "nn_pred <- predict(nn_model, validation_scaled, type = \"class\")\n",
    "nn_accuracy <- accuracy_func(validation_set$quality_category, nn_pred)\n",
    "results_df <- rbind(results_df, data.frame(Method = \"Neural Network\", Accuracy = nn_accuracy))\n",
    "\n",
    "cat(\"Method 4 completed: Neural Network\\n\")\n",
    "\n",
    "# Method 5: Enhanced Random Forest\n",
    "set.seed(42)\n",
    "tuned_rf <- randomForest(quality_category ~ ., \n",
    "                         data = train_set_final[, c(feature_cols, \"quality_category\")],\n",
    "                         ntree = 1000,\n",
    "                         mtry = 10,\n",
    "                         importance = TRUE,\n",
    "                         nodesize = 2)\n",
    "tuned_rf_pred <- predict(tuned_rf, validation_set)\n",
    "tuned_rf_accuracy <- accuracy_func(validation_set$quality_category, tuned_rf_pred)\n",
    "results_df <- rbind(results_df, data.frame(Method = \"Enhanced Random Forest\", Accuracy = tuned_rf_accuracy))\n",
    "\n",
    "cat(\"Method 5 completed: Enhanced Random Forest\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ae7fcb",
   "metadata": {},
   "source": [
    "## 8. Weighted Ensemble Model\n",
    "\n",
    "We'll combine predictions from individual models using weighted probabilities to create an ensemble classifier. Like having a wine tasting panel where everyone's opinion matters (but some more than others)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9bfeed",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cat(\"Creating Weighted Ensemble - combining the wisdom of all our models...\\n\")\n",
    "set.seed(42)\n",
    "\n",
    "# Get prediction probabilities from all models\n",
    "rf_probs <- predict(rf_model, validation_set, type = \"prob\")\n",
    "svm_probs <- attr(predict(svm_model, validation_set, probability = TRUE), \"probabilities\")\n",
    "nn_probs <- predict(nn_model, validation_scaled, type = \"raw\")\n",
    "tuned_rf_probs <- predict(tuned_rf, validation_set, type = \"prob\")\n",
    "\n",
    "# Calculate weights based on individual model performance\n",
    "model_accuracies <- c(rf_accuracy, svm_accuracy, nn_accuracy, tuned_rf_accuracy)\n",
    "ensemble_weights <- model_accuracies / sum(model_accuracies)\n",
    "\n",
    "cat(\"Ensemble weights based on performance:\\n\")\n",
    "cat(\"Random Forest:\", round(ensemble_weights[1], 3), \"\\n\")\n",
    "cat(\"SVM:\", round(ensemble_weights[2], 3), \"\\n\")\n",
    "cat(\"Neural Network:\", round(ensemble_weights[3], 3), \"\\n\")\n",
    "cat(\"Enhanced RF:\", round(ensemble_weights[4], 3), \"\\n\")\n",
    "\n",
    "# Weighted ensemble prediction\n",
    "weighted_probs <- ensemble_weights[1] * rf_probs + \n",
    "  ensemble_weights[2] * svm_probs[,c(\"Low\",\"Medium\",\"High\")] + \n",
    "  ensemble_weights[3] * nn_probs + \n",
    "  ensemble_weights[4] * tuned_rf_probs\n",
    "\n",
    "ensemble_pred <- factor(colnames(weighted_probs)[apply(weighted_probs, 1, which.max)], \n",
    "                        levels = c(\"Low\", \"Medium\", \"High\"))\n",
    "ensemble_accuracy <- accuracy_func(validation_set$quality_category, ensemble_pred)\n",
    "results_df <- rbind(results_df, data.frame(Method = \"Weighted Ensemble\", Accuracy = ensemble_accuracy))\n",
    "\n",
    "cat(\"Method 6 completed: Weighted Ensemble (our potential 90%+ superstar!)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e06a01",
   "metadata": {},
   "source": [
    "## 9. Feature Importance Visualization\n",
    "\n",
    "Let's visualize the top features contributing to wine quality prediction using model importance scores. Which of our engineered features are the real MVPs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126a0aa0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "best_model_idx <- which.max(results_df$Accuracy[1:6])\n",
    "if(results_df$Method[best_model_idx] == \"Weighted Ensemble\") {\n",
    "  importance_df <- data.frame(\n",
    "    Feature = names(importance(tuned_rf)[, \"MeanDecreaseGini\"]),\n",
    "    Importance = importance(tuned_rf)[, \"MeanDecreaseGini\"]\n",
    "  ) %>%\n",
    "    arrange(desc(Importance)) %>%\n",
    "    slice_head(n = 10) %>%\n",
    "    mutate(Feature = reorder(Feature, Importance))\n",
    "  subtitle_text <- \"Ensemble champion reveals the wine secrets (our features are legends!)\"\n",
    "} else {\n",
    "  importance_df <- data.frame(\n",
    "    Feature = names(importance(tuned_rf)[, \"MeanDecreaseGini\"]),\n",
    "    Importance = importance(tuned_rf)[, \"MeanDecreaseGini\"]\n",
    "  ) %>%\n",
    "    arrange(desc(Importance)) %>%\n",
    "    slice_head(n = 10) %>%\n",
    "    mutate(Feature = reorder(Feature, Importance))\n",
    "  subtitle_text <- \"Enhanced Random Forest picks its favorites (engineered features FTW!)\"\n",
    "}\n",
    "p4 <- importance_df %>%\n",
    "  ggplot(aes(x = Feature, y = Importance, fill = Importance)) +\n",
    "  geom_col(alpha = 0.8) +\n",
    "  coord_flip() +\n",
    "  scale_fill_gradient(low = \"#E8F4F8\", high = \"#2E86AB\") +\n",
    "  labs(title = \"Feature Importance: What Actually Predicts Wine Quality\",\n",
    "       subtitle = subtitle_text,\n",
    "       x = \"Features (Original + Our Engineered Ones)\",\n",
    "       y = \"Importance Score\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"none\",\n",
    "        plot.title = element_text(size = 14, face = \"bold\"),\n",
    "        plot.subtitle = element_text(size = 12))\n",
    "print(p4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0189c4",
   "metadata": {},
   "source": [
    "## 10. Model Performance Comparison\n",
    "\n",
    "Let's compare validation accuracies of all models, including the ensemble, using a bar chart. Can our ensemble break the 90% barrier? üèÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4586839",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "performance_df <- results_df[1:6, ]\n",
    "p5 <- performance_df %>%\n",
    "  ggplot(aes(x = reorder(Method, Accuracy), y = Accuracy, fill = Accuracy)) +\n",
    "  geom_col(alpha = 0.8) +\n",
    "  geom_text(aes(label = round(Accuracy, 3)), hjust = -0.1) +\n",
    "  coord_flip() +\n",
    "  scale_fill_gradient(low = \"#FFE5E5\", high = \"#2E8B57\") +\n",
    "  labs(title = \"Model Performance Championship\",\n",
    "       subtitle = \"Can our Ensemble break the 90% barrier? üèÜ\",\n",
    "       x = \"Machine Learning Models\",\n",
    "       y = \"Validation Accuracy\") +\n",
    "  ylim(0, 1) +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"none\",\n",
    "        plot.title = element_text(size = 14, face = \"bold\"),\n",
    "        plot.subtitle = element_text(size = 12))\n",
    "print(p5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0f942f",
   "metadata": {},
   "source": [
    "## 11. Final Test Evaluation\n",
    "\n",
    "We'll apply the best model to the test set and calculate final accuracy. Time for the final taste test with our champion!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e958d1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "best_model_idx <- which.max(results_df$Accuracy)\n",
    "best_method <- results_df$Method[best_model_idx]\n",
    "\n",
    "cat(\"\\nBest validation method:\", best_method, \"\\n\")\n",
    "cat(\"Validation accuracy:\", round(results_df$Accuracy[best_model_idx], 4), \"\\n\")\n",
    "\n",
    "# Apply best model to test set\n",
    "if(best_method == \"Weighted Ensemble\") {\n",
    "  test_scaled <- test_set\n",
    "  for(col in numeric_cols) {\n",
    "    col_mean <- mean(train_set_final[[col]])\n",
    "    col_sd <- sd(train_set_final[[col]])\n",
    "    test_scaled[[col]] <- (test_set[[col]] - col_mean) / col_sd\n",
    "  }\n",
    "  rf_test_probs <- predict(rf_model, test_set, type = \"prob\")\n",
    "  svm_test_probs <- attr(predict(svm_model, test_set, probability = TRUE), \"probabilities\")\n",
    "  nn_test_probs <- predict(nn_model, test_scaled, type = \"raw\")\n",
    "  tuned_rf_test_probs <- predict(tuned_rf, test_set, type = \"prob\")\n",
    "  weighted_test_probs <- ensemble_weights[1] * rf_test_probs + \n",
    "    ensemble_weights[2] * svm_test_probs[,c(\"Low\",\"Medium\",\"High\")] + \n",
    "    ensemble_weights[3] * nn_test_probs + \n",
    "    ensemble_weights[4] * tuned_rf_test_probs\n",
    "  final_pred <- factor(colnames(weighted_test_probs)[apply(weighted_test_probs, 1, which.max)], \n",
    "                       levels = c(\"Low\", \"Medium\", \"High\"))\n",
    "} else if(grepl(\"Enhanced Random Forest\", best_method)) {\n",
    "  final_pred <- predict(tuned_rf, test_set)\n",
    "} else if(best_method == \"Random Forest\") {\n",
    "  final_pred <- predict(rf_model, test_set)\n",
    "} else if(best_method == \"SVM (RBF Kernel)\") {\n",
    "  final_pred <- predict(svm_model, test_set)\n",
    "} else {\n",
    "  test_scaled <- test_set\n",
    "  for(col in numeric_cols) {\n",
    "    col_mean <- mean(train_set_final[[col]])\n",
    "    col_sd <- sd(train_set_final[[col]])\n",
    "    test_scaled[[col]] <- (test_set[[col]] - col_mean) / col_sd\n",
    "  }\n",
    "  final_pred <- predict(nn_model, test_scaled, type = \"class\")\n",
    "}\n",
    "final_accuracy <- accuracy_func(test_set$quality_category, final_pred)\n",
    "results_df <- rbind(results_df, data.frame(Method = \"Final Test Accuracy\", Accuracy = final_accuracy))\n",
    "\n",
    "cat(\"\\n=== RESULTS SUMMARY ===\\n\")\n",
    "cat(\"Drumroll please... ü•Å\\n\")\n",
    "print(results_df)\n",
    "\n",
    "if(final_accuracy >= 0.90) {\n",
    "  cat(\"\\nüéâ MISSION ACCOMPLISHED! We broke the 90% barrier! üéâ\\n\")\n",
    "  cat(\"Our ensemble wine-judging AI is now better than most humans! üç∑\\n\")\n",
    "} else {\n",
    "  cat(sprintf(\"\\nüìà Final accuracy: %.1f%% - Getting close to sommelier level!\\n\", final_accuracy * 100))\n",
    "  cat(\"Still better than my wine-picking skills at the grocery store! üõí\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97618606",
   "metadata": {},
   "source": [
    "## 12. Confusion Matrix and Per-Class Metrics\n",
    "\n",
    "We'll compute and display the confusion matrix, precision, recall, and F1-score for each class on the test set. More detailed than a sommelier's tasting notes (and hopefully more accurate)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a575db8",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cat(\"\\nFinal Test Set Confusion Matrix:\\n\")\n",
    "conf_matrix <- table(Predicted = final_pred, Actual = test_set$quality_category)\n",
    "print(conf_matrix)\n",
    "\n",
    "precision <- diag(conf_matrix) / rowSums(conf_matrix)\n",
    "recall <- diag(conf_matrix) / colSums(conf_matrix)\n",
    "f1 <- 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "cat(\"\\nPer-class Performance:\\n\")\n",
    "performance_summary <- data.frame(\n",
    "  Class = names(precision),\n",
    "  Precision = round(precision, 3),\n",
    "  Recall = round(recall, 3),\n",
    "  F1_Score = round(f1, 3)\n",
    ")\n",
    "print(performance_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570877a7",
   "metadata": {},
   "source": [
    "## 13. Execution Time Tracking\n",
    "\n",
    "Let's measure and display the total execution time for the analysis. Still faster than waiting for your Uber after wine tasting! üç∑\n",
    "\n",
    "üéâ Analysis complete! Our weighted ensemble can now judge wine better than that friend who only drinks box wine but claims to be an expert! With our ensemble approach combining multiple models, we're targeting true sommelier-level accuracy! üèÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61ceb7e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "end_time <- Sys.time()\n",
    "total_time <- as.numeric(difftime(end_time, start_time, units = \"mins\"))\n",
    "cat(\"\\nTotal execution time:\", round(total_time, 2), \"minutes\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
